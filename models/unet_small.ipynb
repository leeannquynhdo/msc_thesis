{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset, random_split\n",
    "import torchvision.transforms.functional as TF\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "import datetime\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "should_train = True\n",
    "\n",
    "path_to_trained_model = 'models_final/unet_test_local/trained_unet_model.pth'\n",
    "path_to_train_loss = 'models_final/unet_test_local/unet_train_losses.txt'\n",
    "path_to_val_loss = 'models_final/unet_test_local/unet_val_losses.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class convolution(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_c)\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_c)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.conv1(data)\n",
    "        x = self.batch_norm1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batch_norm2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.conv = convolution(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2,2))\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.conv(data)\n",
    "        p = self.pool(x)\n",
    "        return x, p\n",
    "\n",
    "class decoder(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = convolution(out_c + out_c, out_c)\n",
    "        \n",
    "    def forward(self, data, skip): # skip connections\n",
    "        x = self.up(data)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "class unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        \"\"\" Encoding \"\"\"\n",
    "        self.en1 = encoder(1, 64)\n",
    "        self.en2 = encoder(64, 128)\n",
    "        self.en3 = encoder(128, 256)\n",
    "        self.en4 = encoder(256, 512)\n",
    "\n",
    "        \n",
    "        # \"\"\" Bottleneck \"\"\"\n",
    "        self.bottle = convolution(512, 1024)\n",
    "        \n",
    "        # \"\"\" Decoding \"\"\"\n",
    "        self.de1 = decoder(1024, 512)\n",
    "        self.de2 = decoder(512, 256)\n",
    "        self.de3 = decoder(256, 128)\n",
    "        self.de4 = decoder(128, 64)\n",
    "        \n",
    "        \"\"\" Classifier \"\"\"\n",
    "        self.last = nn.Conv2d(64, 1, kernel_size=1, padding=0)\n",
    "    \n",
    "    def forward(self, data):\n",
    "        \"\"\" Encoding \"\"\"\n",
    "        s1, p1 = self.en1(data)\n",
    "        s2, p2 = self.en2(p1)\n",
    "        s3, p3 = self.en3(p2)\n",
    "        s4, p4 = self.en4(p3)\n",
    "        \n",
    "        # \"\"\" Bottleneck \"\"\"\n",
    "        b = self.bottle(p4)\n",
    "        \n",
    "        # \"\"\" Decoding \"\"\"\n",
    "        d1 = self.de1(b, s4)\n",
    "        d2 = self.de2(d1, s3)\n",
    "        d3 = self.de3(d2, s2)\n",
    "        d4 = self.de4(d3, s1)\n",
    "        \n",
    "        \"\"\" Classifier \"\"\"\n",
    "        outs = self.last(d4)\n",
    "        \n",
    "        return torch.sigmoid(outs)\n",
    "\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, ids):\n",
    "        self.ids = ids\n",
    "\n",
    "    def transform(self, train_data, train_labels):\n",
    "        return TF.to_tensor(train_data), TF.to_tensor(train_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "\n",
    "        X = TF.to_tensor(Image.open(f\"/Users/leeannquynhdo/Datalogi/MSc_thesis/unet_implementation/line_images/img_{id}.png\"))\n",
    "        y = TF.to_tensor(Image.open(f\"/Users/leeannquynhdo/Datalogi/MSc_thesis/unet_implementation/line_images/mask_{id}.png\"))\n",
    "        \n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"batch_size\": 1, # batch size should be one to avoid re-batching of already batched data. Dataset class returns batched data\n",
    "          \"shuffle\": True,}\n",
    "        #   \"num_workers\": 4,}\n",
    "\n",
    "all_ids = range(100)\n",
    "\n",
    "# Define the split lengths\n",
    "train_len = int(len(all_ids) * 0.6)\n",
    "val_len = int(len(all_ids) * 0.2)\n",
    "test_len = len(all_ids) - train_len - val_len\n",
    "\n",
    "# Use random_split to split the dataset\n",
    "train_data, val_data, test_data = random_split(\n",
    "    Dataset(all_ids),\n",
    "    [train_len, val_len, test_len]\n",
    ")\n",
    "\n",
    "training_generator= DataLoader(train_data, **params)\n",
    "validation_generator = DataLoader(val_data, **params)\n",
    "test_generator = DataLoader(test_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU?: False\n"
     ]
    }
   ],
   "source": [
    "print(\"GPU?:\", torch.cuda.is_available())\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "unet_model = unet().to(device)\n",
    "loss_func = nn.BCELoss().to(device)\n",
    "optimizer = optim.Adam(unet_model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "# ### Functions to train model\n",
    "def training_step(model, dataset):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "\n",
    "    for batch_pair in dataset:\n",
    "        optimizer.zero_grad()\n",
    "        train_images = batch_pair[0].to(device)\n",
    "        train_labels = batch_pair[1].to(device)\n",
    "        outputs = model(train_images)\n",
    "        # print(outputs)\n",
    "        loss = loss_func(outputs, train_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(dataset)\n",
    "\n",
    "def validation_step(model, dataset):\n",
    "    model.eval()\n",
    "    validation_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_pair in dataset:\n",
    "            val_images = batch_pair[0].to(device)\n",
    "            val_labels = batch_pair[1].to(device)\n",
    "            val_outputs = model(val_images)\n",
    "            validation_loss += loss_func(val_outputs, val_labels).item()\n",
    "    return validation_loss / len(dataset)\n",
    "\n",
    "def train_until_convergence(model, train_set, val_set, epochs, patience):\n",
    "    best_val_loss = np.inf\n",
    "    no_improvement = 0\n",
    "    time_diff = 0\n",
    "    train_loss_list = []\n",
    "    val_loss_list = []\n",
    "\n",
    "    total_start = datetime.datetime.now()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = datetime.datetime.now()\n",
    "        sys.stdout.write(\"\\rCurrently at epoch: \" + str(epoch+1) + \". Estimated time remaining: {}\\n\".format(time_diff*(epochs - epoch)))\n",
    "\n",
    "        train_loss = training_step(model, train_set)\n",
    "        val_loss = validation_step(model, val_set)\n",
    "        train_loss_list.append(train_loss)\n",
    "        val_loss_list.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: \\t Training Loss: {train_loss}, \\t Validation Loss: {val_loss}\")\n",
    "\n",
    "        end_time = datetime.datetime.now()\n",
    "        time_diff = end_time - start_time\n",
    "\n",
    "        if (epoch%50==0): #save every model every 50th iter\n",
    "            torch.save(model.state_dict(), f'models_final/unet_test_local/unet_model_mse_epoch_{epoch}.pth' )\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            no_improvement = 0\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "\n",
    "        if no_improvement >= patience:\n",
    "            print(f\"No improvement in validation loss for {patience} epochs. Stopping training...\")\n",
    "            break\n",
    "\n",
    "    total_end = datetime.datetime.now()\n",
    "    total_time = total_end-total_start\n",
    "    print(\"Total running time for unet_lon\", total_time)\n",
    "    \n",
    "    return model, train_loss_list, val_loss_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently at epoch: 1. Estimated time remaining: 0\n",
      "Epoch 1: \t Training Loss: 0.2217104136943817, \t Validation Loss: 0.09844397492706776\n",
      "Currently at epoch: 2. Estimated time remaining: 8:32:46.173841\n",
      "Epoch 2: \t Training Loss: 0.06296202093362809, \t Validation Loss: 0.09465408977121115\n",
      "Currently at epoch: 3. Estimated time remaining: 7:54:24.233808\n",
      "Epoch 3: \t Training Loss: 0.030356917437165974, \t Validation Loss: 0.038785685785114765\n",
      "Currently at epoch: 4. Estimated time remaining: 8:13:17.548764\n",
      "Epoch 4: \t Training Loss: 0.018020158726722003, \t Validation Loss: 0.04369545471854508\n",
      "Currently at epoch: 5. Estimated time remaining: 7:57:11.907520\n",
      "Epoch 5: \t Training Loss: 0.012019593253110845, \t Validation Loss: 0.019240303430706263\n",
      "Currently at epoch: 6. Estimated time remaining: 7:48:43.910100\n",
      "Epoch 6: \t Training Loss: 0.008378676325082778, \t Validation Loss: 0.06860718303360044\n",
      "Currently at epoch: 7. Estimated time remaining: 7:58:05.393906\n",
      "Epoch 7: \t Training Loss: 0.006493943735646704, \t Validation Loss: 0.015075977239757777\n",
      "Currently at epoch: 8. Estimated time remaining: 8:01:22.363588\n",
      "Epoch 8: \t Training Loss: 0.004829925034816066, \t Validation Loss: 0.026526606804691256\n",
      "Currently at epoch: 9. Estimated time remaining: 7:56:42.786048\n",
      "Epoch 9: \t Training Loss: 0.0037403800563576323, \t Validation Loss: 0.02109338608570397\n",
      "Currently at epoch: 10. Estimated time remaining: 7:58:37.109144\n",
      "Epoch 10: \t Training Loss: 0.0029569669937094052, \t Validation Loss: 0.058111250272486356\n",
      "Currently at epoch: 11. Estimated time remaining: 7:45:36.374900\n",
      "Epoch 11: \t Training Loss: 0.002422381048866858, \t Validation Loss: 0.014590720331761986\n",
      "Currently at epoch: 12. Estimated time remaining: 7:44:22.333932\n",
      "Epoch 12: \t Training Loss: 0.0020405886539568503, \t Validation Loss: 0.013396295439451932\n",
      "Currently at epoch: 13. Estimated time remaining: 7:46:49.994152\n",
      "Epoch 13: \t Training Loss: 0.001705041661625728, \t Validation Loss: 0.00962202824302949\n",
      "Currently at epoch: 14. Estimated time remaining: 7:59:54.671245\n",
      "Epoch 14: \t Training Loss: 0.0014911706345931937, \t Validation Loss: 0.004551954014459625\n",
      "Currently at epoch: 15. Estimated time remaining: 7:54:57.981978\n",
      "Epoch 15: \t Training Loss: 0.0012800776593697568, \t Validation Loss: 0.02310481127933599\n",
      "Currently at epoch: 16. Estimated time remaining: 8:00:43.550430\n",
      "Epoch 16: \t Training Loss: 0.0011053194806057338, \t Validation Loss: 0.006071216386044398\n",
      "Currently at epoch: 17. Estimated time remaining: 8:00:51.163044\n",
      "Epoch 17: \t Training Loss: 0.000987248202242578, \t Validation Loss: 0.004113034153124318\n",
      "Currently at epoch: 18. Estimated time remaining: 7:59:04.388736\n",
      "Epoch 18: \t Training Loss: 0.0008984690114933377, \t Validation Loss: 0.004397031114785932\n",
      "Currently at epoch: 19. Estimated time remaining: 7:58:15.374504\n",
      "Epoch 19: \t Training Loss: 0.0008237428759457543, \t Validation Loss: 0.006167919817380607\n",
      "Currently at epoch: 20. Estimated time remaining: 7:53:18.766214\n",
      "Epoch 20: \t Training Loss: 0.0007029095082543791, \t Validation Loss: 0.015092606551479548\n",
      "Currently at epoch: 21. Estimated time remaining: 7:49:01.265280\n",
      "Epoch 21: \t Training Loss: 0.0006152512030287956, \t Validation Loss: 0.00891504634928424\n",
      "Currently at epoch: 22. Estimated time remaining: 7:50:43.934188\n",
      "Epoch 22: \t Training Loss: 0.0005561897793086246, \t Validation Loss: 0.018065909130382352\n",
      "Currently at epoch: 23. Estimated time remaining: 7:50:08.616954\n",
      "Epoch 23: \t Training Loss: 0.0005046543898060918, \t Validation Loss: 0.024702821235405282\n",
      "Currently at epoch: 24. Estimated time remaining: 7:48:15.075333\n",
      "Epoch 24: \t Training Loss: 0.0004584019169366608, \t Validation Loss: 0.005307422552141361\n",
      "Currently at epoch: 25. Estimated time remaining: 7:47:05.787580\n",
      "Epoch 25: \t Training Loss: 0.00041913659370038656, \t Validation Loss: 0.008854954819253181\n",
      "Currently at epoch: 26. Estimated time remaining: 7:47:18.204525\n",
      "Epoch 26: \t Training Loss: 0.00038676404607637476, \t Validation Loss: 0.005872209066001233\n",
      "Currently at epoch: 27. Estimated time remaining: 7:45:57.914508\n",
      "Epoch 27: \t Training Loss: 0.00035844571830239146, \t Validation Loss: 0.026907985587604343\n",
      "Currently at epoch: 28. Estimated time remaining: 7:44:49.534475\n",
      "Epoch 28: \t Training Loss: 0.0010221663556876591, \t Validation Loss: 0.03972008333075792\n",
      "Currently at epoch: 29. Estimated time remaining: 7:42:07.821248\n",
      "Epoch 29: \t Training Loss: 0.0008042286198663835, \t Validation Loss: 0.02670573770737974\n",
      "Currently at epoch: 30. Estimated time remaining: 7:44:33.095637\n",
      "Epoch 30: \t Training Loss: 0.0006517520911681155, \t Validation Loss: 0.04402952561504207\n",
      "Currently at epoch: 31. Estimated time remaining: 7:42:07.757160\n",
      "Epoch 31: \t Training Loss: 0.00038785390061093496, \t Validation Loss: 0.04954985822550952\n",
      "Currently at epoch: 32. Estimated time remaining: 7:41:00.288978\n",
      "Epoch 32: \t Training Loss: 0.0003332711276016198, \t Validation Loss: 0.013105773453571602\n",
      "Currently at epoch: 33. Estimated time remaining: 7:40:56.946720\n",
      "Epoch 33: \t Training Loss: 0.0002735638918238692, \t Validation Loss: 0.04337496240477776\n",
      "Currently at epoch: 34. Estimated time remaining: 7:33:56.606099\n",
      "Epoch 34: \t Training Loss: 0.00024150984487884367, \t Validation Loss: 0.011198923953634221\n",
      "Currently at epoch: 35. Estimated time remaining: 7:35:55.828204\n",
      "Epoch 35: \t Training Loss: 0.00021805685125097322, \t Validation Loss: 0.02282511847151909\n",
      "Currently at epoch: 36. Estimated time remaining: 7:34:05.741745\n",
      "Epoch 36: \t Training Loss: 0.00020014839295375472, \t Validation Loss: 0.018888583279476734\n",
      "Currently at epoch: 37. Estimated time remaining: 7:31:42.845984\n",
      "Epoch 37: \t Training Loss: 0.00018515083938837052, \t Validation Loss: 0.027299139414390085\n",
      "No improvement in validation loss for 20 epochs. Stopping training...\n",
      "Total running time for unet_lon 0:36:11.123817\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if should_train:\n",
    "\n",
    "    # # Train the model LET's FuCKING SKRRRrrRT\n",
    "\n",
    "    trained_model, train_losses, val_losses = train_until_convergence(unet_model, training_generator, validation_generator, epochs=500, patience=20)\n",
    "    # save the trained model\n",
    "    torch.save(trained_model.state_dict(), path_to_trained_model)\n",
    "    # print('train losses:', train_losses)\n",
    "\n",
    "\n",
    "    # write loss to file\n",
    "    with open(path_to_train_loss, 'w') as f:\n",
    "        for loss in train_losses:\n",
    "            f.write(\"%s\\n\" % loss)\n",
    "    \n",
    "    with open(path_to_val_loss, 'w') as f:\n",
    "        for loss in val_losses:\n",
    "            f.write(\"%s\\n\" % loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the trained model\n",
    "trained_model = unet().to(device)\n",
    "trained_model.load_state_dict(torch.load(path_to_trained_model, map_location=device)) # path to trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_step(model, dataset):\n",
    "    model.eval()\n",
    "    test_images = []\n",
    "    test_labels = []\n",
    "    test_outputs = []\n",
    "    with torch.no_grad():\n",
    "        for batch_pair in dataset:\n",
    "            test_image = batch_pair[0].to(device)\n",
    "            # print(test_image)\n",
    "            test_label = batch_pair[1].to(device)\n",
    "            # print(test_label)\n",
    "            test_output = model(test_image)\n",
    "            # print(test_output)\n",
    "            \n",
    "            test_images.append(test_image.detach().cpu())\n",
    "            test_labels.append(test_label.detach().cpu())\n",
    "            test_outputs.append(test_output.detach().cpu())\n",
    "    return test_images, test_labels, test_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels, test_outputs = test_step(trained_model, test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_images)):\n",
    "    fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "    ax[0].imshow(test_images[i].squeeze(0).permute(1,2,0), cmap='gray')\n",
    "    ax[0].set_title('image')\n",
    "    ax[1].imshow(test_labels[i].squeeze(0).permute(1,2,0), cmap='gray')\n",
    "    ax[1].set_title('ground truth')\n",
    "    ax[2].imshow(test_outputs[i].squeeze(0).permute(1,2,0), cmap='gray')\n",
    "    ax[2].set_title('prediction')\n",
    "    # plt.show()\n",
    "    plt.savefig(f'/Users/leeannquynhdo/Datalogi/MSc_thesis/unet_implementation/models_final/unet_test_local/lon_unet_test_result_{i}.png', dpi=500, bbox_inches='tight')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = np.loadtxt(path_to_train_loss)\n",
    "val_losses = np.loadtxt(path_to_val_loss)\n",
    "\n",
    "loss_x = list(range(len(train_losses)))\n",
    "plt.plot(loss_x, train_losses, label='Train loss')\n",
    "plt.plot(loss_x, val_losses, label='Validation loss')\n",
    "plt.title('Train / Validation loss')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/leeannquynhdo/Datalogi/MSc_thesis/unet_implementation/models_final/unet_test_local/unet_train_val_loss.png', dpi=500, bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9956756591796875\n",
      "iou: tensor(0.0985)\n",
      "f1: 0.17926440776136696\n"
     ]
    }
   ],
   "source": [
    "predictions = torch.stack(test_outputs)\n",
    "labels = torch.stack(test_labels)\n",
    "\n",
    "# assuming predictions and labels are PyTorch tensors with shape [4, 4096, 4096, 1]\n",
    "predictions = predictions.squeeze().view(-1)\n",
    "labels = labels.squeeze().view(-1)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, ts = roc_curve(labels.int().view(-1).numpy(), predictions.view(-1).numpy())\n",
    "auc = roc_auc_score(labels.int().view(-1).numpy(), predictions.view(-1).numpy())\n",
    "\n",
    "plt.title('U-Net ROC curve')\n",
    "plt.plot(fpr, tpr, label=f'AUC score = {auc}')\n",
    "plt.legend()\n",
    "plt.savefig('/Users/leeannquynhdo/Datalogi/MSc_thesis/unet_implementation/models_final/unet_test_local/roc_curve_mse.png', dpi=500, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "predictions = (predictions > 0.5).float()\n",
    "\n",
    "accuracy = torch.eq(predictions, labels).sum().item() / len(predictions)\n",
    "print(\"accuracy:\", accuracy)\n",
    "\n",
    "def calculate_iou(pred, target):\n",
    "    intersection = torch.logical_and(pred, target).sum()\n",
    "    union = torch.logical_or(pred, target).sum()\n",
    "    iou = intersection.float() / union.float()\n",
    "    return iou\n",
    "\n",
    "iou = calculate_iou(predictions, labels)\n",
    "print(\"iou:\", iou)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1 = f1_score(labels.int(), predictions.int())\n",
    "print(\"f1:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
